{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Convert binary OPUS files to csv-style text files.\"\n",
    "        )\n",
    "    \n",
    "    file_import = parser.add_mutually_exclusive_group(required=True)\n",
    "    file_import.add_argument(\"-f\", \"--file\", metavar=\"path\", type=str, nargs=\"+\", action=\"store\", help=\"File or files to be converted.\")\n",
    "    file_import.add_argument(\"-d\", \"--dir\", metavar=\"path\", type=str, nargs=1, action=\"store\", help=\"Directory containing the files to be converted\")\n",
    "    parser.add_argument(\"-o\", \"--out\",metavar=\"path\", type=str, nargs=1, action = \"store\", help=\"Output directory for converted files\", required=True)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.dir:\n",
    "        files = os.listdir(args.dir[0])\n",
    "        dir = args.dir[0]\n",
    "    else:\n",
    "        files = args.file\n",
    "        dir = \"\"\n",
    "\n",
    "    return files, dir, args.out[0]\n",
    "\n",
    "files, dir, out_dir = parse_arguments()\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "\n",
    "    print(f\"File {i+1}/{len(files)}.\") # Progress counter\n",
    "\n",
    "    filepath = os.path.join(dir, file)\n",
    "    outpath = os.path.join(out_dir, file + \".txt\")\n",
    "\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    data = data.split(sep=b'END\\x00') # Split into data segments\n",
    "    for i, segment in enumerate(data):\n",
    "        if segment[-4:] == b'OK\\x00\\x00' and data[i+1][-4:] == b'WN\\x00\\x00': # Find segment containing Raman data (Wavenumbers and Intensities)\n",
    "            wn_data = data[i+1]\n",
    "            int_data = data[i+2]\n",
    "            break\n",
    "\n",
    "    wn_data = [wn_data[j:j+4] for j in range(0, len(wn_data), 4)] # Split into 4 Byte junks\n",
    "    \n",
    "    for j in range(len(wn_data)):\n",
    "        if wn_data[j] == b'NPT\\x00': # Number of data points\n",
    "            npt = struct.unpack(\"<I\", wn_data[j+2])[0] # Unsigned Integer, little Endian\n",
    "        if wn_data[j] == b'FXV\\x00': # First Wavenumber\n",
    "            fxv = struct.unpack(\"<d\", b''.join(wn_data[j+2:j+4]))[0] # Double float, Little Endian\n",
    "        if wn_data[j] == b'LXV\\x00': # Last Wavenumber\n",
    "            lxv = struct.unpack(\"<d\", b''.join(wn_data[j+2:j+4]))[0] # Double float, Little Endian\n",
    "\n",
    "    # print(f\"{npt}, {fxv}, {lxv}\")\n",
    "\n",
    "    wns = np.linspace(fxv, lxv, npt) # Create Wavenumber array\n",
    "\n",
    "    int_data = int_data[8:8+npt*4] # Remove leading zeros and split into 4 Byte junks\n",
    "    int_data = [int_data[j:j+4] for j in range(0, len(int_data), 4)]\n",
    "\n",
    "    ints = np.zeros(npt) # Prepare empty array for Intensity data\n",
    "    for j, val in enumerate(int_data):\n",
    "        ints[j] = struct.unpack(\"<f\", val)[0] # Float, Little Endian\n",
    "    \n",
    "    data_out = np.vstack((wns, ints)).T # Combine into one array\n",
    "\n",
    "    np.savetxt(outpath, data_out, delimiter=\",\", fmt=\"%.6f\")\n",
    "    \n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
